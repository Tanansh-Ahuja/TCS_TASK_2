# ğŸ” RAG-based Q&A System using FastAPI + Groq + Chroma

This project implements a **Retrieval-Augmented Generation (RAG)** backend using:

- ğŸ§  **FastAPI** for the API
- ğŸ“š **LangChain** for chaining logic
- ğŸ“¦ **Chroma** for vector database storage
- ğŸ¤— **HuggingFace** for embeddings
- âš¡ **Groq**'s blazing fast LLMs for answering questions

Upload any `.txt` or `.pdf` document and ask questions â€” the model retrieves the most relevant content and gives a contextual answer!

---

## âœ… Features

- ğŸ“„ Upload documents in `.txt` or `.pdf` format
- ğŸ”— Store and retrieve chunks using ChromaDB
- ğŸ§  Ask natural language questions
- ğŸ¤– Powered by `llama3-70b-8192` model from Groq
- ğŸ’¡ Uses `sentence-transformers/all-MiniLM-L6-v2` for embeddings

---

## ğŸ§± Architecture

```
Your Document (.pdf / .txt)
      â†“
LangChain Loaders & Text Splitters
      â†“
HuggingFace Embeddings (Vectorized)
      â†“
Chroma DB (for storage & search)
      â†“
User Question â†’ Embedding â†’ Similar Chunks
      â†“
LLM (Groq) with Context â†’ Final Answer
```

---

## âš ï¸ Issues Faced & Fixes

| Problem | Resolution |
|--------|------------|
| âŒ `mixtral-8x7b-32768` model decommissioned | âœ… Switched to `llama3-70b-8192` |
| âŒ `OpenAIEmbeddings` threw 401 error with Groq key | âœ… Used `HuggingFaceEmbeddings` instead |
| âŒ `GroqEmbeddings` not found | âœ… It's not a real class â€” use HuggingFace for embeddings |
| âŒ Only `.txt` supported initially | âœ… Added `.pdf` support using `PyMuPDFLoader` |

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Clone the Repo

```bash
git clone <your-repo-url>
cd <project-folder>
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Create a `.env` File

```env
GROQ_API_KEY=gsk_********************************
```

### 4ï¸âƒ£ Run the Server

```bash
uvicorn main:app --reload
```

---

## ğŸ“¤ Uploading a File

- **Endpoint:** `POST /upload/`
- **Body (form-data):**
  - `file`: Choose a `.pdf` or `.txt` file

âœ… Example via **Postman** or any frontend.

---

## â“ Asking a Question

- **Endpoint:** `POST /ask/`
- **Body (JSON):**
```json
{
  "question": "What is this document about?"
}
```

ğŸ“© Response:
```json
{
  "question": "What is this document about?",
  "answer": "The document discusses..."
}
```

---

## ğŸ“¦ `requirements.txt`

```txt
fastapi
uvicorn
python-dotenv
langchain
langchain-community
langchain-core
langchainhub
langchain-groq
huggingface-hub
sentence-transformers
chromadb
PyMuPDF
```

---

## ğŸ§ª Example Use Case

Upload a resume and ask:
> "What are the candidate's strengths?"

Or upload a project document and ask:
> "What are the key features mentioned?"

---

## ğŸ§‘â€ğŸ’» Author

Built by **Tanansh** for Task 2 of a Retrieval-Augmented Generation project using Groq's API.

---

## ğŸ“š References

- [Groq Console](https://console.groq.com/)
- [LangChain Docs](https://docs.langchain.com/)
- [Chroma](https://docs.trychroma.com/)
- [HuggingFace Embeddings](https://huggingface.co/sentence-transformers)


## ğŸ That's it!

